<!DOCTYPE html>
<html>
<head>
<meta charset=UTF-8>
<meta http-equiv="Pragma" content="no-cache">
<meta http-equiv="Cache-Control" content="no-cache">
<meta http-equiv="Expires" content="0">
</head>
<body>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>

人工知能学会 言語・音声理解と対話処理研究会（SLUD）第91回研究会を
下記の要領でオンライン開催いたします．

各締切の日程は下記のとおりです．

　　発表申込締切日：　　2021年1月15日（水）
　　資料集原稿締切日：　2021年2月1日（月）
　　資料集発行日：      2021年2月20日（土）

今回のSLUDでは，通常の一般セッションに加え，特別セッション「対話の分析・
モデル化・自動処理」を設けます．本特別セッションは，対話データ（人間同
士の対話および人間と機械の対話のデータ）を対象とした様々な研究を人文系
・理工系の双方から発表して頂くことで，今後の連携の促進を図るものです．
既発表の内容でも構いません．また，ポジション発表やサーベイ発表も歓迎し
ます．

本特別セッションでは以下の招待講演を予定しています．

    宇佐美まゆみ先生（国立国語研究所）
       「人間同士の自然会話分析への多角的アプローチ
             －総合的会話分析と対話データの自動処理（仮）」
    増村 亮先生（NTTメディアインテリジェンス研究所）
       「複数人会話データを活用した音声言語処理とアプリケーション」

たくさんのお申込みをお待ちしております．

==============================
第91回 言語・音声理解と対話処理研究会

日時：2021年3月1日（月），2日（火)
会場：オンライン開催

参加費：無料
資料集：希望者に有償で郵送（電子版の購入も可能）
参加・発表資格：特になし
　　　　　      人工知能学会および本研究会非会員の方でも参加・発表可能

発表申込締切日：　　2021年1月15日（水）
資料集原稿締切日：　2021年2月1日（月）
資料集発行日：      2021年2月20日（土）

発表申込先：下記URLより，必要事項をご記入の上，お申し込みください．
別途学会事務局より，執筆案内をお送りいたします．

https://www.ai-gakkai.or.jp/sig-system/sigusers/presenter_add/slud/slud91
（アブストラクトは400字まで）

問合わせ先（担当幹事）：中野 幹生（C4A研究所）
Email: mikio.nakano（at）c4a.jp

備考：
・セッションの振り分けは，研究会にお任せいただきます．
・発表時間については，質疑応答を含め，30分とさせていただく予定です．
・研究会が対象とする分野の範囲外，あるいは，研究会発表にふさわしい分量・質に
達していない申し込みについてはお断りすることがありますので，予めご了解ください．
・情報保障等特別なサポートを希望される方はご相談ください．可能な範囲で対応致します．
・人工知能学会研究会への投稿論文に関する著作権規程が2017年7月に
制定されました（過去の著作物にも遡って適用されます）．
発表者の皆様におかれましては，同規定を遵守の上，原稿のご執筆をお願いいたします．
https://www.ai-gakkai.or.jp/pdf/sig/sig_copyright.pdf

==============================
募集内容
(a) 特別セッション：「対話の分析・モデル化・自動処理」
(b) 一般セッション

---------------------------------------------------------------
(a) 特別セッション：「対話の分析・モデル化・自動処理」
---------------------------------------------------------------
主旨：

　対話データ（人間同士の対話および人間と機械の対話のデータ）を用いた研
究は，言語学，心理学，社会学，情報学などの様々な分野で行われています．
SLUD研究会ではこれまでも，様々な分野の対話研究が発表されており，課題や
情報の共有に役立ってきたと考えていますが，まだ不十分な面があると思われ
ます．そこで，今回の研究会においては，対話データを用いたあらゆる研究を
対象にしたテーマセッションを開くことで，分野間の連携を促進したいと考え
ています．

招待講演：

　本特別セッションでは以下の招待講演を予定しています．

    宇佐美まゆみ先生（国立国語研究所）
       「人間同士の自然会話分析への多角的アプローチ
             －総合的会話分析と対話データの自動処理（仮）」
    増村 亮先生（NTTメディアインテリジェンス研究所）
       「複数人会話データを活用した音声言語処理とアプリケーション」

募集する発表：

　本特別セッションで募集する発表が扱う研究トピック，対話データの種類，
発表の内容の例として，以下のようなものがありますが，これに限定するもの
ではありません．

研究トピック：
・対話へのアノテーションの内容・ガイドライン・ツール
・対話の語用論的分析
・対話の社会言語学的分析
・対話の認知言語学的分析
・対話の心理言語学的分析
・話者交替の定性的分析・定量的分析・モデル化
・対話の構造の定性的分析・定量的分析・モデル化
・対話における基盤化の定性的分析・定量的分析・モデル化
・対話における社会的信号の定性的分析・定量的分析・自動処理
・対話参加者の感情・態度の定性的分析・定量的分析・自動処理
・参加者の感情・対話に対する印象の自動推定
・対話の自動要約，自動分類，自動翻訳
・対話における参照表現の分析と処理
・対話参加者に関する情報の自動抽出
・対話データを対象にした情報検索
・対話データの収集と分析に関する倫理的な問題に関する議論

研究対象とする対話データの種類
・1対1の対話／3人以上の会話
・物理的な対面対話／オンライン対面対話／電話対話／テキスト対話／手話対話
・雑談／目標のある対話
・人間同士の対話／機械またはWizard of Ozが対話参加者に入っている対話

発表内容
・研究成果の発表（著作権に留意頂ければ既発表の成果でも構いません）
・サーベイ発表
・ポジション発表

特別セッションの原稿のページ数は2-6ページとします．

--------------------------------------------------------------
(b) 一般セッション
--------------------------------------------------------------
下記分野を中心に発表を募集いたします．

音声対話モデル，対話による概念理解と形成，対話のためのプランニング，
音声処理，音声言語処理，自然言語理解，自然言語処理，計算言語学，
統計的言語モデル，マルチモーダル・インタラクション，
マルチメディア・インターフェイス技術，インタラクティブ・システム，
コミュニケーションモデル，ユーザモデリング，意図理解，心理モデル，
社会言語学，理論言語学，認知言語学，認知意味論

一般セッションの投稿原稿のページ数は，SLUD の投稿規程（基本は6ページ）
に準じます．

===========================      
※人工知能学会の研究会資料(第一種)の扱いについて
　2015年4月以降に人工知能学会第一種研究会に投稿された研究会資料は紙冊子に
掲載されると同時に，学会事務局で資料ID（※１）を付与した上で学会文献提供
サイト「AI書庫」(https://jsai.ixsq.nii.ac.jp/ej/ )上のPDFファイルとして閲覧可能と
なります．
 発行日(※２)から一年間は，一本あたり(非会員 600円＋消費税，学会員 300円
＋消費税，登録会員 0円)にて販売します．一年間の保留期間(エンバーゴ)後は
無料購読できるようになりオンライン公開されます．
 なおAI書庫上のデータには，標準的な識別子(番号)は付与されませんが，一般的な
検索エンジンや国立情報学研究所が提供するCiNiiなどから容易に検索できるように
なります．

(※１)研究会資料ID付与規則の変更(2015年度より)
研究会資料ID（論文ID）の付与ルールを下記のように統一しました．
　   資料ID: [研究会名略称]-[巻(3桁)]-[号(2桁)]　 例：SIG-SWO-021-03
　　   巻： 研究会の通算の開催回数       例：21
　　   号： 特定の回での論文の発表順     例：3
　　   頁： 研究会毎に以下の何れかのポリシーで付与する．
　　   A) 各回でページナンバリングしている場合は，そのページ情報を使用
　　   B) そうでない場合には，発表毎に「pp. 1-論文のページ分量」
(※２)紙媒体の奥付に記載された発行日
============================        

</code></pre></div>
</body>
</html>
