<!DOCTYPE html>
<html>
<head>
<meta charset=UTF-8>
<meta http-equiv="Pragma" content="no-cache">
<meta http-equiv="Cache-Control" content="no-cache">
<meta http-equiv="Expires" content="0">
</head>
<body>
  <div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>

人工知能学会 言語・音声理解と対話処理研究会（SLUD）第94回研究会のプログラムが決まりましたので，ご案内いたします．

今回のSLUDでは，通常の一般セッションに加え，特別セッション「相互行為のなかのこころ」を設けております．
本特別セッションでは，千葉大学の西阪仰先生，および，ヨーテボリ大学のJonas Ivarsson先生による招待講演を予定しております．

また，今回は発表申込数が予定よりも多かったため，急遽3月5日（土）午後を日程に追加しました．

皆様のご参加を心よりお待ち申し上げております．

==============================
第94回 言語・音声理解と対話処理研究会（SLUD）

日時：2022年3月5日（土）・6日（日）
会場：オンライン開催
参加費：無料
参加資格：特になし（人工知能学会および本研究会非会員の方でも参加可能）
参加方法：以下のWebページより事前登録をお願いいたします．
研究会数日前にZoom URLを送信いたします．
https://www.ai-gakkai.or.jp/sig-system/sigusers/add/slud/slud94 
資料集：冊子もしくは電子版で提供いたします
［研究会会員・賛助会員］冊子を郵送（発行日：2月25日（金）以降）
［非会員］
電子版（1,500円）
                【通販サイト：https://jsaioffice.stores.jp/ 】（販売開始日：2月25日（金））
冊子（2,000円，送料，手数料，税込）※申込締切：2月24日（木）
                【申込先：https://forms.gle/P2CiaELpsJUEixhGA 】
［人工知能学会学生会員］
 	電子版（無料）※申込締切：2月24日（木）
                【申込先：https://forms.gle/P2CiaELpsJUEixhGA 】

照会先：黒嶋 智美（玉川大学）
Email: skuroshi [at] lab.tamagawa.ac.jp

備考：
      情報保障等特別なサポートを希望される方はご相談ください．
      可能な範囲で対応致します．


==============================
プログラム（発表は目安として発表20分、質疑10分）

【一日目：3月5日（土）】

13:45		Zoomオープン

13:55-14:00	オープニング

14:00-15:30	一般セッション1（90分）
1-1.	多人数ビデオ会話における非言語情報に基づく次話者予測
水野沙希，北条伸克，小橋川哲，増村亮（NTT）

1-2.	非タスク指向対話システムにおけるからかいユーモア応答の生成
上垣貴嗣，清水健吾，菊池英明（早稲田大学）

1-3.	テレビ視聴時における人同士の発話を用いた応答文生成と評価
星祐太，奥田誠，萩尾勇太，上村真利奈，金子豊，西本友成（NHK放送技術研究所）

15:30-15:40	休憩（10分）

15:40-17:40	一般セッション2 （120分）
2-1. 	暫定的に基盤化された知識を投機的に用いたTNT対話の分析
須藤早喜，浅野恭四郎（静岡大学），光田航，東中竜一郎（NTT）
竹内勇剛（静岡大学）

2-2.	音声言語獲得ツールキットSpolacq
小松亮太．豊田啓介．木村友祐，森滉介，日野健人，篠崎隆宏（東京工業大学）

2-3. 	強化学習を用いてキャラクタらしさを付与した雑談応答の生成
清水健吾，上垣貴嗣，菊池英明（早稲田大学）

2-4. 	指示表現の調整を通した対話における基盤化モデル
浅野恭四郎，須藤早喜（静岡大学），光田航，東中竜一郎（NTT），竹内勇剛（静岡大学）


【二日目：3月6日（日）】

8:45		Zoomオープン

8:55-9:00	事務連絡

9:00-10:30	一般セッション3（90分）
3-1.	意外性，新規性および具体性を考慮したユーモアを含む直喩表現生成
井上恵彰，谷津元樹，森田武史（青山学院大学）

3-2.	汎用的言語理解フレームワークへのボケ検出機構の統合
掛川夏海，谷津元樹，森田武史（青山学院大学）

3-3.	初対面の高齢女性二者会話における親疎関係の調整プロセス
鈴木奈央，徳永弘子，山田晴奈（東京電機大学）
楊井一彦，髙栁直人，平石牧子（花王株式会社）
武川直樹（東京電機大学）

10:30-10:40	休憩（10分）

10:40-12:40	一般セッション4（120分）
4-1.	JLCATのスピーキング評価基準再考ー非言語コミュニケーションの視点からー
叶暁峰（國學院大學）

4-2.	依頼連鎖の開始に用いられる謝罪表現「ごめん」
梁勝奎（名古屋大学）

4-3.	オンライン会話における発話重複 ―先行発話への阻害に着目して―
中矢明歩，岡本雅史（立命館大学）

4-4.	オンライン会議における発話間のオーバーラップの分析
細馬宏通，村岡春視（早稲田大学）

12:40-13:40	昼休憩（60分）

13:40-14:40	特別セッション 招待講演１
	相互行為における「見ること」と「触れること」: 「詳細を調べること」と行為の構成 
	西阪仰（千葉大学）

14:40-14:50	休憩（10分）

14:50-16:20	特別セッション1（90分）
5-1.	大規模事前学習対話モデルを用いた説得対話システム
有岡無敵（奈良先端科学技術大学院大学），吉野幸一郎（理化学研究所）
中村哲（奈良先端科学技術大学院大学）

5-2.	日本語説得対話に対するFace Actのアノテーションとその応用に向けて
河野誠也，波部英子，湯口彰重，吉野幸一郎（理化学研究所）

5-3.	交渉印象推定のためのマルチモーダル交渉対話コーパスの作成と評価
北条伸克，小橋川哲，水野沙希，増村亮（NTT）

16:20-16:30	休憩（10分）

16:30-17:30	特別セッション2（60分）
6-1.	相互行為のなかの認識――外科手術場面の会話分析より
黒嶋智美（玉川大学）

6-2.	医療場面の意思決定過程における感情について
川島理恵（京都産業大学）

17:30-17:40	休憩（10分）

17:40-18:40	特別セッション 招待講演２
	Understanding Trust and Conversational Agents
Jonas Ivarsson (University of Gothenburg, Sweden)

18:40-18:50 	クロージング

19:00-20:00 	オンライン懇親会


-------------------------------------------------------------------

特別セッション：「相互行為のなかのこころ」

-------------------------------------------------------------------

本特別セッションでは，2つの招待講演と，相互行為のなかにたち現れる様々
な心的概念についての経験的分析による研究発表を予定しています．認識，理
解，認知，感情など，様々な心的概念が私たちの文化、社会に存在しますが，
それらの概念を私たちは普段どのように区別し使用しているのかについて考え
るセッションです．様々な分野, 視点, アプローチからの発表を通して活発な
議論が出来ればと存じます.


招待講演１：

西阪 仰 先生（千葉大学）

相互行為における「見ること」と「触れること」: 「詳細を調べること」と行為の構成


概要：

相互行為において，「詳細を調べる」とでも呼ぶべき振舞いが，しばしば観察
される．特定の対象に対して，目を近づけ，視線をしばらく固定すること，な
どである．この報告では，とくに，同時にその対象に手で触れながら「詳細を
調べる」ことをあえてすることが，特定行為の構成を回避するための手続きと
して用いられることが示す．さらに，視覚と触覚は，相互行為における特定行
為の構成のなかで，分かちがたく結びつき，身体の多様な動きの時間的空間的
配列の，すなわちその特定行為を形作る全体構造の一部となっている．そのな
かで，参加者たちは，相手がある対象に触れているのを見るだけではなく，相
手がその対象を感じているかを見るという複合感覚的な状況が成立する．この
点も，具体的に示してみたい．


招待講演２：

Prof. Jonas Ivarsson (University of Gothenburg, Sweden)

Understanding Trust and Conversational Agents


概要：

The presentation starts with the recent developments of natural language
processing. The quality and interactivity of voice-based interactive
services are sometimes so good that the artificial cannot be differentiated
from real persons. This means that interactions can be successful without
the artificial agent becoming identified as synthetic. However, in such
encounters, can it also be said that the interlocutors have understood each
other? In what ways do understanding figure in real-world human-computer
interactions? The argument will be made that we need two parallel
conceptions of understanding to address these questions. By departing from
ethnomethodology and conversation analysis, it is illustrated how parties
in a conversation regularly deploy two forms of analysis (categorical and
sequential) to understand their interactional partner. The interplay
between these forms of analysis shapes the developing sense of
interactional exchanges and is crucial for established relations, including
the feelings of trust and suspicion. The address concludes that the
proliferation of conversational systems fueled by artificial intelligence
may have unintended consequences, including its impacts on human-human
interactions.

</code></pre></div>
</body>
</html>
